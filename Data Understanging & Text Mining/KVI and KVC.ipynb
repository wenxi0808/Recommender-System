{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other than product categories and sub-categories, are there other product groupings, e.g., \n",
    "#  Key Value Items (KVI) and Key Value Categories (KVC), traffic drivers, always promoted versus seldom/never promoted, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Construct credentials from service account key file\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    'tche368-isom676-srvacct_srvacct.json')  # Update the file path as needed\n",
    "\n",
    "# Construct a BigQuery client object\n",
    "client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "# Revised and optimized query\n",
    "QUERY = \"\"\"\n",
    "WITH product_filter AS (\n",
    "    SELECT *\n",
    "    FROM `machine_learning.products`\n",
    "    WHERE prod_category NOT IN (\"Gift Cards\", \"Other\", \"Front End Service\", \"Scanning Errors\", \"Customer Service-Misc\", \"Empties and Additionals\")\n",
    "),\n",
    "valid_transactions AS (\n",
    "    SELECT *\n",
    "    FROM `machine_learning.transactions` a \n",
    "    join product_filter b on a.prod_id  = b.prod_id \n",
    "    WHERE trans_dt < \"2020-03-01\"\n",
    "    AND a.prod_id IN (SELECT prod_id FROM product_filter)\n",
    "        AND \n",
    "        -- Logic 1: Either sales_qty or sales_wgt is zero, but not both\n",
    "        ((sales_qty = 0 AND sales_wgt <> 0) OR (sales_qty <> 0 AND sales_wgt = 0))\n",
    "        AND \n",
    "        -- Logics 2 and 3 are parallel conditions\n",
    "        (\n",
    "            (prod_category NOT IN (\"Coupon\", \"returns\") AND (sales_qty > 0 OR sales_wgt > 0))\n",
    "            OR\n",
    "            (prod_category IN (\"Coupon\", \"returns\") AND (sales_qty < 0 OR sales_wgt < 0))\n",
    "        )\n",
    "    AND sales_amt >= 0\n",
    "),\n",
    "transactions_per_day AS (\n",
    "    SELECT cust_id, trans_dt, COUNT(DISTINCT trans_id) AS trans_per_day\n",
    "    FROM valid_transactions\n",
    "    GROUP BY cust_id, trans_dt\n",
    "    HAVING trans_per_day <= 10\n",
    "),\n",
    "eligible_custs AS (\n",
    "    SELECT v.cust_id\n",
    "    FROM valid_transactions v\n",
    "    JOIN transactions_per_day tpd ON v.cust_id = tpd.cust_id AND v.trans_dt = tpd.trans_dt\n",
    "    GROUP BY v.cust_id\n",
    "    HAVING COUNT(DISTINCT v.trans_id) >= 5\n",
    "    AND COUNT(DISTINCT v.trans_dt) >= 5\n",
    "    AND COUNT(v.trans_id) <= 20000\n",
    "),\n",
    "sampled_custs AS (\n",
    "    SELECT cust_id\n",
    "    FROM eligible_custs\n",
    "    WHERE MOD(ABS(FARM_FINGERPRINT(CAST(cust_id AS STRING))), 1000) < 1\n",
    ")\n",
    "SELECT tx.*\n",
    "FROM `valid_transactions` tx\n",
    "JOIN sampled_custs ON tx.cust_id = sampled_custs.cust_id\n",
    "WHERE tx.trans_dt < \"2020-03-01\"\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(QUERY)  # API request\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_transaction = query_job.to_dataframe()  # Waits for query to finish and converts it to DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load product and profit margin data\n",
    "product_profit_margin_df = pd.read_excel(\"C:/Users/ctlan/OneDrive/desktop/AI at Scale/HW/Product Category Profit Margin.xlsx\")\n",
    "\n",
    "# Merge with product_profit_margin to get profit margins\n",
    "merged_df = pd.merge(sample_transaction, product_profit_margin_df, on='prod_category', how='left')\n",
    "\n",
    "# Calculate profit for each transaction\n",
    "merged_df['profit'] = merged_df['sales_amt'] * merged_df['profit_margin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## customer clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming sample_transaction and product_profit_margin_df have been loaded correctly\n",
    "# Load the product_profit_margin_df\n",
    "product_profit_margin_df = pd.read_excel(\"C:/Users/ctlan/OneDrive/desktop/AI at Scale/HW/Product Category Profit Margin.xlsx\")\n",
    "\n",
    "# Merge with product_profit_margin to get profit margins\n",
    "merged_df = pd.merge(sample_transaction, product_profit_margin_df, on='prod_category', how='left')\n",
    "\n",
    "# Calculate profit for each transaction\n",
    "merged_df['profit'] = merged_df['sales_amt'] * merged_df['profit_margin']\n",
    "\n",
    "# KVI: Identify top 10 KVI based on total profit\n",
    "kvi_top10 = merged_df.groupby('prod_id').agg(total_profit=('profit', 'sum')).reset_index().sort_values('total_profit', ascending=False).head(10)\n",
    "\n",
    "# KVC: Identify top 10 KVC based on total profit\n",
    "kvc_top10 = merged_df.groupby('prod_category').agg(total_profit=('profit', 'sum')).reset_index().sort_values('total_profit', ascending=False).head(10)\n",
    "\n",
    "# Traffic items: Identify top 10 products based on sales quantity\n",
    "traffic_top10 = merged_df.groupby('prod_id').agg(total_sales_qty=('sales_qty', 'sum')).reset_index().sort_values('total_sales_qty', ascending=False).head(10)\n",
    "\n",
    "# Add 'Type' columns for differentiation\n",
    "kvi_top10['Type'] = 'KVI'\n",
    "kvc_top10['Type'] = 'KVC'\n",
    "traffic_top10['Type'] = 'Traffic'\n",
    "\n",
    "# Prepare KVC for final DataFrame (adjusting for consistent column names)\n",
    "kvc_top10['prod_id'] = kvc_top10['prod_category']\n",
    "\n",
    "# Create an empty list to hold data\n",
    "data = []\n",
    "\n",
    "# Add KVI data\n",
    "for index, row in kvi_top10.iterrows():\n",
    "    data.append({'Category': 'KVI', 'Ranking_Type': 'Profit', 'Value': row['prod_id']})\n",
    "\n",
    "# Add KVC data\n",
    "for index, row in kvc_top10.iterrows():\n",
    "    data.append({'Category': 'KVC', 'Ranking_Type': 'Profit', 'Value': row['prod_category']})  # Use prod_category for clarity\n",
    "\n",
    "# Add Traffic data\n",
    "for index, row in traffic_top10.iterrows():\n",
    "    data.append({'Category': 'Traffic', 'Ranking_Type': 'Sales Quantity', 'Value': row['prod_id']})\n",
    "\n",
    "# Convert list to DataFrame\n",
    "final_output_df = pd.DataFrame(data)\n",
    "\n",
    "final_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of profit for each product\n",
    "kvi_sum_profit = merged_df.groupby('prod_id')['profit'].sum().reset_index().rename(columns={'profit': 'sum_profit'})\n",
    "\n",
    "# Sort the products based on the sum of profit and get top 10 KVI\n",
    "kvi_top10 = kvi_sum_profit.sort_values('sum_profit', ascending=False).head(10)\n",
    "\n",
    "# Calculate the sum of profit for each product category\n",
    "kvc_sum_profit = merged_df.groupby('prod_category')['profit'].sum().reset_index().rename(columns={'profit': 'sum_profit'})\n",
    "\n",
    "# Sort the categories based on the sum of profit and get top 10 KVC\n",
    "kvc_top10 = kvc_sum_profit.sort_values('sum_profit', ascending=False).head(10)\n",
    "\n",
    "# Calculate the sum of sales amount for each product to identify traffic drivers\n",
    "traffic_sum_sales_amt = merged_df.groupby('prod_id')['sales_amt'].sum().reset_index().rename(columns={'sales_amt': 'sum_sales_amt'})\n",
    "\n",
    "# Sort the products based on the sum of sales amount to get top 10 traffic driving products\n",
    "traffic_top10 = traffic_sum_sales_amt.sort_values('sum_sales_amt', ascending=False).head(10)\n",
    "\n",
    "# Note: The resulting top 10 lists for KVI, KVC, and Traffic Drivers are stored in kvi_top10, kvc_top10, and traffic_top10 respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvi_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvc_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 promote products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming sample_transaction has been loaded\n",
    "\n",
    "# Exclude transactions with 'Coupons' category and 'In-Store'\n",
    "sample_transaction_filtered = sample_transaction[(sample_transaction['prod_category'] != 'Coupons') & (sample_transaction['prod_category'] != 'In-Store')]\n",
    "\n",
    "# Convert transaction dates to datetime format and extract the month\n",
    "sample_transaction_filtered['month'] = pd.to_datetime(sample_transaction_filtered['trans_dt']).dt.to_period('M')\n",
    "\n",
    "# Group by product and month to calculate monthly sales quantities, excluding 'Coupons'\n",
    "monthly_sales_qty = sample_transaction_filtered.groupby(['prod_id', 'month'])['sales_qty'].sum().reset_index()\n",
    "\n",
    "# Calculate the standard deviation of sales quantities for each product, fill NaN with 0\n",
    "std_sales_qty = monthly_sales_qty.groupby('prod_id')['sales_qty'].std().fillna(0).reset_index().rename(columns={'sales_qty': 'std_sales_qty'})\n",
    "\n",
    "# Determine \"Often Promoted\" threshold as the 75th percentile of standard deviations\n",
    "threshold = std_sales_qty['std_sales_qty'].quantile(0.75)\n",
    "\n",
    "# Identify \"Often Promoted\" products based on the threshold\n",
    "std_sales_qty['promotion_frequency'] = std_sales_qty['std_sales_qty'].apply(lambda x: 'Often Promoted' if x >= threshold else 'Seldom/Never Promoted')\n",
    "\n",
    "# Get top 20 \"Often Promoted\" products excluding 'Coupons', sorted by their standard deviation\n",
    "top_20_often_promoted = std_sales_qty[std_sales_qty['promotion_frequency'] == 'Often Promoted'].sort_values('std_sales_qty', ascending=False).head(20)\n",
    "\n",
    "# Merge with unique prod_id to prod_category mapping to add 'prod_category', excluding 'Coupons'\n",
    "prod_id_to_category = sample_transaction_filtered[['prod_id', 'prod_category']].drop_duplicates()\n",
    "top_20_often_promoted_with_category = pd.merge(top_20_often_promoted, prod_id_to_category, on='prod_id', how='left')\n",
    "\n",
    "# The resulting DataFrame has top 20 often promoted products, excluding 'Coupons', with their categories\n",
    "top_20_often_promoted_with_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
